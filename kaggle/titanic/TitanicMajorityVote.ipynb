{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Majority Vote Ensemble"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "This model will combine the power of logistic regression, K Nearest Neighbors, Support Vector Machine, and Random Forest classifiers to predict the survival of passengers on the Titanic. The dataset comes from Kaggle."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import warnings\nwarnings.filterwarnings('ignore')",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Importing the training data, cleaning it, and creating X and y arrays of the inputs and known outputs:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data = pd.read_csv('train.csv')\ndf = data.fillna({'Age': 29.7, 'Embarked':'S'})\n\ndummies = pd.get_dummies(df.Sex)\ndf = pd.concat([df,dummies], axis = 'columns')\ndummies2 = pd.get_dummies(df.Embarked)\ndf = pd.concat([df,dummies2], axis = 'columns')\ndf.drop(['PassengerId','Name','Ticket','Cabin','Sex','male','Embarked','S'], axis = 1, inplace = True)\nX = df.iloc[:,1:9].values\ny = df.iloc[:,0].values",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Splitting into training and test sets:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1, stratify = y)",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Building the model"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Importing the neccessary libraries for a Majority Vote classifier:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.svm import SVC",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The four classifiers to be feed into the Majority Vote:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "clf1 = LogisticRegression(penalty = 'l2', C = 10, random_state = 1)\nclf2 = KNeighborsClassifier(n_neighbors = 1, p =2, metric = 'minkowski')\nclf3 = SVC(C = 1, gamma = 0.1, kernel = 'rbf', probability = True)\nclf4 = RandomForestClassifier(random_state = 1)",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Work-flow pipelines for the first three classifiers above. Note that these classifiers require the input data to be feature scaled, while the random forest classifier does not."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pipe1 = Pipeline([['sc', StandardScaler()],['clf', clf1]])\npipe2 = Pipeline([['sc', StandardScaler()],['clf', clf2]])\npipe3 = Pipeline([['sc', StandardScaler()],['clf', clf3]])",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Setting up the Majority Vote classifier:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "clf_labels = ['Logistics Regression', 'KNN', 'SVM','Decision Tree', 'Majority Vote']\n\nmv_clf = VotingClassifier(estimators = [(clf_labels[0], pipe1), \n                                        (clf_labels[1], pipe2), \n                                        (clf_labels[2], pipe3),\n                                        (clf_labels[3], clf4)], \n                          voting = 'soft')",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Comparing the accuracy of all classifiers:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "all_clf = [pipe1, pipe2, pipe3, clf4, mv_clf]\nfor clf, label in zip(all_clf,clf_labels):\n    scores = cross_val_score(estimator = clf, X = X_train, y = y_train, cv = 10, scoring = 'roc_auc')\n    print(\"Accuracy : %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Accuracy : 0.86 (+/- 0.06) [Logistics Regression]\nAccuracy : 0.74 (+/- 0.05) [KNN]\nAccuracy : 0.86 (+/- 0.06) [SVM]\nAccuracy : 0.84 (+/- 0.05) [Decision Tree]\nAccuracy : 0.87 (+/- 0.05) [Majority Vote]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "### Fitting the model"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Importing and cleaning the testing data:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data2 = pd.read_csv('test.csv')\ndf2 = data2.fillna({'Age': 29.7, 'Embarked':'S'})\n\ndummies = pd.get_dummies(df2.Sex)\ndf2 = pd.concat([df2,dummies], axis = 'columns')\ndummies2 = pd.get_dummies(df2.Embarked)\ndf2 = pd.concat([df2,dummies2], axis = 'columns')\ndf2.drop(['PassengerId','Name','Ticket','Cabin','Sex','male','Embarked','S'], axis = 1, inplace = True)\nx_test = df2.iloc[:,:].values\nx_test[152,4] = df2['Fare'].mean()",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Running the fit() and predict() methods:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "mv_clf = mv_clf.fit(X_train, y_train)\n\ny_pred = mv_clf.predict(x_test)",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "y_pred",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1,\n       1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1,\n       1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1,\n       1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n       1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n       0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n       1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0])"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
